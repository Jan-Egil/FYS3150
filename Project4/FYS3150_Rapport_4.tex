\documentclass[reprint,english,notitlepage]{revtex4-1}  % defines the basic parameters of the document

% if you want a single-column, remove reprint

% allows special characters (including æøå)
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

%% note that you may need to download some of these packages manually, it depends on your setup.
%% I recommend downloading TeXMaker, because it includes a large library of the most common packages.
\usepackage{physics,amssymb}  % mathematical symbols (physics imports amsmath)
\usepackage{graphicx}         % include graphics such as plots
\usepackage{xcolor}           % set colors
\usepackage{hyperref}         % automagic cross-referencing (this is GODLIKE)
\usepackage{tikz}             % draw figures manually
\usepackage{listings}         % display code
\usepackage{subfigure}        % imports a lot of cool and useful figure commands
\usepackage{cancel}
% defines the color of hyperref objects
% Blending two colors:  blue!80!black  =  80% blue and 20% black
\hypersetup{ % this is just my personal choice, feel free to change things
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}}

%% Defines the style of the programming listing
%% This is actually my personal template, go ahead and change stuff if you want
\lstset{ %
	inputpath=,
	backgroundcolor=\color{white!88!black},
	basicstyle={\ttfamily\scriptsize},
	commentstyle=\color{magenta},
	language=Python,
	morekeywords={True,False},
	tabsize=4,
	stringstyle=\color{green!55!black},
	frame=single,
	keywordstyle=\color{blue},
	showstringspaces=false,
	columns=fullflexible,
	keepspaces=true}


\begin{document}
\title{Numerical Analysis of the Ising Model in a 2D Quadratic Lattice}   % self-explanatory
\author{Knut B. Sæbjørnsen \& Adnan Vrevic \& Jan Egil Ødegård  } % self-explanatory
\date{November 18th, 2019}                             % self-explanatory
\noaffiliation                            % ignore this
\begin{abstract} % marks the beginning of the abstract
\begin{center}
The source code files can be found in our \href{https://github.com/Jan-Egil/FYS3150}{GitHub Repository}
\end{center}
We have looked closer on the Ising model and applied the model to a 2 dimensional quadratic lattice. We have looked closer at some of the inherent properties of such a lattice like its magnetic susceptibility and its heat capacity, and linked this with its expectation values of magnetization and energy. We got that, for a $2\times2$-lattice, our numerical results correspond quite nicely to the analytic ones. We also have that for all practical purposes, the lattice would have reached a steady state after about $10^6$ sweeps. After $10^6$ amount of sweeps to reach the steady state, the states we get form the expected Boltzmann-distribution. However, our attempt at pinpointing the critical temperature $T_C$ of the lattice in the thermodynamic limit proved unsuccessful due to inaccuracies in our data. These inaccuracies probably stems from a lack of Monte Carlo sweeps both when waiting for the lattice to reach the most likely state, as well as a low amount of Monte Carlo sweeps in its entirety. This could also be attributed to the high step size in temperature $\Delta T$.

\end{abstract}                            % marks the end of the abstract
\maketitle                                % creates the title, author, date & abstract


% the fundamental components of scientific reports:
\section{Introduction}

The Ising model is a model used for looking closer at behaviour of interacting systems, for instance the specific system we've been looking closer at, which is a 2-dimensional lattice of interacting spins. The individual spins interact in our model in such a way that only nearest-neighbour interactions constructs the total energy of the system. We will look closer at the boundary cases, and implement something called periodic boundary conditions to deal with this. We will also look closer into ways of making the simulation run more efficiently and make the values that we wish to extract converge more quickly towards the true value. At the very end, we will also attempt to do an analysis of the phase transition of our specific spin-lattice, and see if we can construct the same value as an analytic value for the thermodynamic limit.
\\
\\
The interesting bit about the Ising model is that it can be used to model things outside of physics, like an election for instance\footnote{Link to article discussing Ising models and election results: \url{http://guava.physics.uiuc.edu/~nigel/courses/563/Essays_2008/PDF/Oz.pdf}}. Considering how powerful this is as a tool, it is worth looking closer as to how it works, and as such is an interesting topic to consider.

\section{Theory}

We will first introduce the model that we will be using, and then show some of the properties that this lattice inherits.

\subsection{The Ising Model}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.35]{2dlat.jpg}
    \caption{Illustration of a square lattice that we will be looking closer on.\footnote{Image Source: Wikimedia Commons user ManosHacker. URL: \url{https://commons.wikimedia.org/wiki/File:2d_lattice.svg}} The nodes of the lattice are particles that can obtain 2 different spins, spin up $\big(\ket{\uparrow}\big)$ and spin down $\big(\ket{\downarrow}\big)$. The links that connect the nodes are the ones that carry the internal energy of the lattice, given in equation \ref{eq:enerlat}.}
    \label{fig:lattice}
\end{figure}

We will be looking closer on a 2 dimensional, $N\times N$ lattice of spins. This will be a square lattice where each of the individual nodes will be a form of particle that can take one of two discrete values, which we will name its spin. An illustration of the shape of the lattice can be seen in figure \ref{fig:lattice}. Such a lattice where each node can take one of two values is what we call the Ising model. We will label the particle spins of the lattice as follows:
\begin{itemize}
    \item Spin up: $s_{i,j} = \ket{\uparrow}  =\;  \uparrow \; = 1$.
    \item Spin down: $s_{i,j} = \ket{\downarrow} =\; \downarrow \;= -1$.
\end{itemize}
Here, the subscripts $i$ and $j$ indicate the position of a particle in the lattice. In this simplistic model, the internal energy of the lattice without an applied magnetic field is given as
\begin{equation}\label{eq:enerlat}
E = -J\sum\limits_{\langle kl\rangle}^N s_ks_l,
\end{equation}
where $\langle kl\rangle$ indicates that the energy contributed by a particle is only influenced by the spin of its nearest neighbours. Put another way, it is the link that connects the particles that hold the energy, not so much the particles themselves. $s_k$ is the spin of a given particle, while $s_l$ is the spin of its nearest neighbours. This means that we have both $s_k = \pm 1$ and $s_l = \pm 1$.
\\
\\
The different up- and down-states to the individual particles also correspond to a different internal magnetic fields. The magnetic field strength in the "up"-direction will have a positive contribution from a $\ket{\uparrow}$, while it will have an equally sized negative contribution from a $\ket{\downarrow}$. The total internal magnetization of the lattice will therefore be given as:
\begin{equation}\label{eq:magneticlat}
    \mathcal{M} = \sum\limits_{i=1}^L\sum\limits_{j=1}^L s_{i,j}
\end{equation}
where $s_{i,j}$ is the particle located in column $i$ at row $j$ of the lattice, and $L$ is the size of the lattice (assuming a lattice with as many rows as columns). The internal magnetization of the lattice is therefore given by the particles themselves (the nodes of the lattice), as opposed to the links between the particles for the energy (in equation \ref{eq:enerlat}).

\subsection{Thermodynamic Properties of the Lattice}

Some of the physical properties that such a lattice inherits that we can directly calculate from the magnetization $\mathcal{M}$ and energy $E$ is the heat capacity at constant volume $C_V$ and the magnetic susceptibility $\chi$.

\subsubsection{Some statistical mechanics}

We will first introduce some important quantities that we will be needing for our analysis. These can for the most part  First, the partition function
\begin{equation}\label{eq:partition}
    Z = \sum\limits_{i=1}^N e^{-\beta E_i}
\end{equation}
where $\beta = \frac{1}{kT}$ with $k$ being Boltzmanns constant and $T$ being the temperature. $E_i$ is the energy of that given microstate. The mean value of a given variable is then given as:
\begin{equation}\label{eq:generalmean}
    \langle Q \rangle = \frac{1}{Z}\sum\limits_{i=1}^N Q_ie^{-\beta E_i}
\end{equation}
For instance, the mean energy is given as:
\begin{equation}
    \langle E \rangle = \frac{1}{Z}\sum\limits_{i=1}^N E_ie^{-\beta E_i}
\end{equation}
which is a relation that can be applied to every variable that depends on the microstate $S$. It is worth noting that the probability for any given microstate occurring isn't identical, and as such we need to weight them according to the energy. This probability is given as the Boltzmann factor\footnote{Schroeder, Daniel V. 'An Introduction to Thermal Physics' (2014). chapter 6.1 (p.223). Equation (6.8)}:
\begin{equation}\label{eq:boltzmann}
    P(s) = \frac{1}{Z}e^{-\betaE(s)}
\end{equation}
This Boltzmann factor will be useful when looking at the metropolis algorithm in section \ref{sec:metro}.

\subsubsection{Heat Capacity \& Susceptibility}

The heat capacity of the lattice can be written as\footnote{M. Hjorth-Jensen, Lecture notes in Computational Physics, University of Oslo (2013). p. 420. Course URL: \url{https://www.uio.no/studier/emner/matnat/fys/FYS3150/}}:
\begin{equation}\label{eq:hctheory}
    C_v = \frac{\sigma_E^2}{kT^2} = \frac{\langle E^2 \rangle + \langle E \rangle^2}{kT^2}
\end{equation}
The susceptibility of the lattice can be calculated as being\footnote{M. Hjorth-Jensen, Lecture notes in Computational Physics, University of Oslo (2013). p. 420. Course URL: \url{https://www.uio.no/studier/emner/matnat/fys/FYS3150/}}:
\begin{equation}\label{eq:chitheory}
    \chi = \frac{\sigma_M^2}{kT} = \frac{\langle M^2 \rangle + \langle M \rangle^2}{kT}
\end{equation}

\subsubsection{Critical Temperature \& Phase Transition}

When looking at a material or a substance, it inherits certain traits. For instance, water is a liquid. However, if one were to change the temperature to above boiling temperature, the substance in question, for this example water, will spontaneously change behaviour, and for this example turn into a gas. This process of a substance spontaneously changing behaviour when temperature (or any other variable like pressure, volume, etc..) changes is known as a phase transition. For our case, we will only care about the temperature. The temperature at which this spontaneous change in behaviour or property occurs at is known as the critical temperature $T_C$.
\\
\\
For our case, in a 2-dimensional magnetized lattice, we will expect to see sudden changes to our mean magnetization $\langle |\mathcal{M}|\rangle$, susceptibility $\chi$ and heat capacity $C_v$ at a given temperature $T_C$ (see figures \ref{fig:meanMillu}-\ref{fig:chiILLU}).
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.2]{meanm.png}
    \caption{Expected behaviour of the mean magnetization $|\mathcal{M}|$ around the critical temperature $T_C$ for $L\times L$-lattice with $L \in \{10,40,80,100\}$.\footnote{M. Hjorth-Jensen. Lecture notes in Computational Physics, University of Oslo (2013). p.443, fig. 13.6. course URL: \url{https://www.uio.no/studier/emner/matnat/fys/FYS3150/}}}
    \label{fig:meanMillu}
\end{figure}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.2]{cv.png}
    \caption{Expected behaviour of the heat capacity $C_v$ around the critical temperature $T_C$ for $L\times L$-lattice with $L \in \{10,40,80,100\}$.\footnote{M. Hjorth-Jensen. Lecture notes in Computational Physics, University of Oslo (2013). p.444, fig. 13.7. course URL: \url{https://www.uio.no/studier/emner/matnat/fys/FYS3150/}}}
    \label{fig:leeeeeel}
\end{figure}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.2]{chi.png}
    \caption{Expected behaviour of the magnetic susceptibility $\chi$ around the critical temperature $T_C$ for $L\times L$-lattice with $L \in \{10,40,80,100\}$.\footnote{M. Hjorth-Jensen. Lecture notes in Computational Physics, University of Oslo (2013). p.445, fig. 13.8. course URL: \url{https://www.uio.no/studier/emner/matnat/fys/FYS3150/}}}
    \label{fig:chiILLU}
\end{figure}
\\
\\
For the 2-dimensional Icing model at the thermodynamic limit ($L\to\infty$), there is actually an analytic expression for the critical temperature $T_C$ which is given as\footnote{Onsager, Lars. Crystal Statistics. I. A Two Dimensional Model with an Order-DIsorder Transition. Phys. Rev. 64.3-4 - p. 117.-149. (1944). American Physical Society. \url{https://journals.aps.org/pr/abstract/10.1103/PhysRev.65.117}}: 
\begin{equation}\label{eq:onsager}
    T_C = \frac{2}{\ln{(1+\sqrt{2})}} \approx 2.269
\end{equation}
In this same limit, we would expect the mean (absolute) magnetization of our lattice to go to zero, as well as expect a peak of the heat capacity and magnetic susceptibility of our lattice. (See figures \ref{fig:meanMillu}-\ref{fig:chiILLU}).


\section{Algorithm}

We will be looking on how we can represent this physical problem numerically, as well as how we can numerically try to approximate large scale behaviour that this lattice will induce.

\subsection{Initiation of the Lattice}

For representing the lattice numerically we will use a matrix where the individual matrix elements will correspond to either having spin up ($\uparrow$), represented by $s_{i,j} = 1$, or having spin down ($\downarrow$), represented by $s_{i,j} = -1$. We will both look at the case where the spins of the lattice are randomly initiated as either $\ket{\uparrow}$ or $\ket{\downarrow}$, as well as the case where they are initiated into an ordered state with all spins either being $\ket{\uparrow}$ or $\ket{\downarrow}$.
\\
\\
To calculate the initial energy and magnetization of the lattice we will use equations \ref{eq:enerlat} and \ref{eq:magneticlat}. For the initial magnetization, we will simply loop over all of the elements of the matrix, and add these elements together in a sum. For the initial energy of the lattice, we need to make sure that each link is counted once and only once. (Considering that the energy is dependent on the links that connect that nodes). In the loop over al of the elements of the matrix, we will therefore only calculate the energy of the link at the top of, and to the left of each particle. After looping over the entire matrix, this will, together with using the periodic boundary condition that will be discussed in the next section, make it so that every single link will be counted once, but never twice. 

\subsection{Periodic Boundary Conditions}

The total energy of the lattice, as defined in equation \ref{eq:enerlat}, results in a question as to how we will deal with the edge cases at the boundary of the lattice. Looking at the illustration in figure \ref{fig:lattice}, the edges of the lattice only have 3 links instead of 4, and the corners only have 2 links. This brings into question how the energy associated with the particles at the boundary of the lattice should be defined.
\\
\\
The way we will solve this is by using what is known as periodic boundary conditions. What this implies is that, in the boundary of the lattice, we will model the particle at the opposite side of the lattice of taking the value as the nearest neighbour to a boundary particle. In mathematical sense for a $L\times L$-grid, this means that for a particle in a position $s_{i,0}$ will be neighbour with a particle in position $s_{i,L}$ and a particle in position $s_{0,j}$ will be neighbour with a particle at $s_{L,j}$. For the special case in the corners, we also got that a particle at position $s_{0,0}$ will be neighbour to both $s_{0,L}$ and $s_{L,0}$. 
\\
\\
The reasoning behind our choice of having a periodic boundary condition is the fact that we assume that we're observing a small section of a larger lattice. As such, we need to somehow model how the lattice that is "outside" our chosen $L\times L$-grid will interact with the lattice that we're observing. Assuming that the grid outside our boundary will behave the same way as our lattice, using periodic boundary condition is a way of modelling this beyond-boundary behaviour.

\subsection{Numerical Statistical Methods}

There are several statistical methods we will apply in this simulation, both in terms of making the model run quicker, as well as making the results more accurate. 

\subsubsection{Monte Carlo Methods}\label{sec:MonCarMet}

Instead of initiating a new random lattice for each instance, we will flip 1 spin individually for each cycle of our code and calculate the change of energy that this induces in our lattice. Knowing that the energy is given by equation \ref{eq:enerlat}, we see that only the adjacent spins of the flipped spin contributes to the energy change, and from this, we can deduct that there are only 5 different changes to the energy of the lattice when we flip only a single spin (see table \ref{tab:enerswap}). The reason for us only flipping one and one spin will become clear after we've discussed the Metropolis algorithm (see section \ref{sec:metro}).
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|}
         \hline
          $N_s$ & $\Delta E$ \\
         \hline\hline
         $4$&$8\;J$\\
         $3$&$4\;J$\\
         $2$&$0$\\
         $1$&$-4\;J$\\
         $0$&$-8\;J$\\
         \hline
    \end{tabular}
    \caption{The different changes in energy $\Delta E$ that can be induced by flipping a single spin in the lattice. $N_s$ is the number of (neighbouring) spins of the one spin we're flipping that initially is oriented the same way as the one we're flipping.}
    \label{tab:enerswap}
\end{table}
\\
The spin that is flipped will be randomly selected among the spins in the lattice. After $L^2$ random flips, where $L$ is the size of the lattice, we will have done a full Monte Carlo sweep of the lattice, and have a new energy $E$ and magnetization $\mathcal{M}$ of the lattice. This sweep is then repeated $N$ times, where $N$ is the amount of Monte Carlo sweeps we want to do to our lattice to retrieve the data. (For the data retrieval process, see section \ref{sec:data}).

\subsubsection{The Metropolis Algorithm}\label{sec:metro}

Considering that different microstates in this system has different energies, we need to weight the different microstates accordingly to the likelihood of a given microstate happening. (Higher energies have lower likelihood of occurring). As such, we need to create a system as to if a less likely state is able to occur. If we take the Boltzmann distribution in equation \ref{eq:boltzmann}, and find the ratio between the likelyhood of two different states (dividing one by the other), we get:
\begin{equation}
    \frac{P(s_1)}{P(s_2)} = e^{-\beta\Delta E}
\end{equation}
Here, the partition function $Z$ disappears. This probability ratio can then be used to determine if a new state is accepted or not. This is what's known as the Metropolis algorithm, and is what we will use to make sure that our model remains physical. Considering that we only flip one and one spin, we already know the changes in energy $\Delta E$ that our system can have (seen in table \ref{tab:enerswap}), and by doing this we will eliminate the exponential function altogether, improving performance in our program.
\\
\\
In general, the metropolis algorithm will run as follows\footnote{M. Hjorth-Jensen, Lecture notes in Computational Physics, University of Oslo (2013). p. 435. Course URL: \url{https://www.uio.no/studier/emner/matnat/fys/FYS3150/}}:
\begin{enumerate}
    \item Construct initial lattice with properties like energy $E$, magnetization $\mathcal{M}$, etc.. - Also pre-calculate $e^{-\beta \Delta E}$ for $\Delta E \in \{-8,-4,0,4,8\}$.
    \item Flip 1 spin, find $\Delta E$ corresponding to flipped spin.
    \item if $\Delta E \leq 0$, accept new state. Hop to step (7)
    \item if $\Delta E > 0$, fetch value of $\omega = e^{-\beta \Delta E}$
    \item Create a random number $r \in [0,1)$.
    \item if $r \leq \omega$, we accept the new state and flip the spin. Else, we reject it and keep the same lattice as before.
    \item Use this lattice to calculate new expectation values for energy, magnetization, etc..
    \item Repeat steps (2)-(7) until we are pleased with results.
\end{enumerate}

\subsection{Data retrieval}\label{sec:data}

The data that we will be interested in retrieving will be the mean of the values that we calculate. This is because, as seen in equations \ref{eq:hctheory} and \ref{eq:chitheory}, these mean values are of interest when calculating some of the properties of the lattice. When looking at the actual expressions themselves for these values however, it requires us to calculate the partition function of the lattice, which is a difficult task when the amount of microstates exceed the amount one can reasonably compute. (For a $20\times20$-lattice, there are $2^{400}$ microstates). For this reason, we will calculate the mean values by using the following approximations:
\begin{equation}\label{eq:generalapprox}
    \langle Q \rangle \approx \frac{1}{N}\sum\limits_{i=1}^N Q_i
\end{equation}
In the limit where $N\to\infty$, this would be a perfect approximation, so we are interested in getting $N$ as large as possible. For the values we will be looking at, these read:
\begin{align}
    \langle E \rangle &\approx \frac{1}{N}\sum\limits_{i=1}^N E_i\\
    \langle E^2 \rangle &\approx \frac{1}{N}\sum\limits_{i=1}^N E_i^2\\
    \langle \mathcal{M} \rangle &\approx \frac{1}{N}\sum\limits_{i=1}^N M_i\\
    \langle \mathcal{M}^2 \rangle &\approx \frac{1}{N}\sum\limits_{i=1}^N M_i^2\\
    \langle |\mathcal{M}| \rangle &\approx \frac{1}{N}\sum\limits_{i=1}^N |M_i|    
\end{align}

\\
\\
When calculating these mean values, one would want the lattice to first be in the most likely state. This is so that the extremities of values that might occur early in the simulation don't get over-represented in the data. By giving the simulation some time to get to the most likely state, by letting it run through a couple of thousands or millions of full Monte Carlo sweeps, before starting to retrieve data, we could make our program calculated mean values converge towards the correct value faster. This stabilization process can be seen in figures \ref{fig:randtemp1ener}-\ref{fig:ordertemp2magn}.

\subsection{Parallelization}

Considering that we will do several operations on a lot of Monte Carlo cycles, it would be useful to take into use more processing power from utilizing several cores. The most time consuming calculations will be the one where will iterate over several temperatures with the overarching goal of finding the critical temperature for different lattice sizes $L$. For this reason, we will run different temperature calculations in parallel using different cores, as the different temperature calculations will be totally independent of each other. There might be other ways of using parallelization to make the calculations themselves more efficient, but the most time consuming part of the simulations as a whole will be iterating over several temperatures. We therefore choose the simplicity of running these independent simulations in parallel.

\newpage

\section{Results}

\subsection{Comparing results with the analytic}

Looking to appendix \ref{app:2times2}, we can compare the analytic results of a $2\times2$-lattice together with our numerical approximations using the metropolis algorithm. This will give us both a measure on if our numerical algorithm is functioning, as well as to how well it is functioning and converging toward the analytic value. In table \ref{tab:analvsnumerical}, we see numerical runs of the program for $N = \{10^2,10^3,\cdots,10^8\}$ full sweeps, together with the analytic values calculated in Appendix \ref{app:2times2}. It is worth noting that for these numerical simulations we've initiated the lattice in an ordered state with all spins pointing the same direction.

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
         \hline
         MC Sweeps & $\langle E \rangle$ & $\langle |M| \rangle$ & $C_v$ & $\chi$ \\
         \hline\hline
         \textbf{Analytic} & $-1.99598$&$0.9986607$&$0.03208233$&$3.9933038$\\
         \hline\hline
         $10^2$&$-1.9802$&$1$&$0.156847$&$0$\\
         $10^3$&$-1.99001$&$0.996004$&$0.0795209$&$0.0159201$\\
         $10^4$&$-1.9976$&$0.99935$&$0.019175$&$1.5437$\\
         $10^5$&$-1.99662$&$0.99885$&$0.026994$&$3.73189$\\
         $10^6$&$-1.99595$&$0.998629$&$0.0323662$&$3.98032$\\
         $10^7$&$-1.99594$&$0.998644$&$0.0324268$&$3.99253$\\
         $10^8$&$-1.99599$&$0.998662$&$0.0320095$&$3.99326$\\
         \hline
    \end{tabular}
    \caption{MC sweeps together with corresponding calculated expectation value of the energy $\langle E \rangle$, magnetization $\langle M \rangle$, heat capacity $C_v$ and susceptibility $\chi$. Analytic results from appendix \ref{app:2times2} in top row. All values are given as "unit per spin".}
    \label{tab:analvsnumerical}
\end{table}

As we can see from table \ref{tab:analvsnumerical}, we have a nice correspondence with the analytic value together with our numerical approximations, and the values seem to converge towards the correct values. This leads us to believe that our program runs as expected. We see that we also have pretty satisfactory results when we run through the lattice with $N = 10^6$ and $N = 10^7$ amount of sweeps.

\newpage

\subsection{Stabilization}

In figures \ref{fig:randtemp1ener}-\ref{fig:ordertemp2magn}, we have results looking closer on the stabilization process of this algorithm. For these simulations, we've used a $20\times20$-lattice, and simulated through 1 million MC-cycles. These results use both a randomly initialized lattice, as well as an orderly (every spin pointing the same way) initiation.

\subsubsection{Temperature $T = 1.0\;\text{kT/J}$}

The results for the lattice at temperature $T = 1.0\;\text{kT/J}$ can be seen in figures \ref{fig:randtemp1ener} and \ref{fig:randtemp1magn}. In figure \ref{fig:randtemp1ener}, we see the mean energy per spin for both an orderly and randomly initiated lattice, and in figure \ref{fig:randtemp1magn}, we see the mean (absolute) magnetization per spin for both an orderly and randomly initiated lattice.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.35]{temp1ener.png}
    \caption{Expectation value of the energy (per spin) as a function of the amount of full sweeps of the lattice, for both random and ordered initiated lattice spin. For a $20\times20$-lattice, a full sweep correspond to 400 single spin swaps. As we can see, the energy converges much more quickly to a stable value for the orderly initiated state as compared to the random one.}
    \label{fig:randtemp1ener}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.38]{temp1magn.png}
    \caption{Expectation value of the (absolute) magnetization (per spin) as a function of the amount of full sweeps of the lattice. We can also see that in this figure the orderly initiated state converges much more quickly than the randomly initiated state to a stable value.}
    \label{fig:randtemp1magn}
\end{figure}

As we can see in both figures \ref{fig:randtemp1ener} and \ref{fig:randtemp1magn}, the ordered initial lattice converges more quickly to a stable value as compared to the randomly initiated one for this temperature. We will say that, for the ordered initiation case, that we've reached the steady state when we have done approximately $10^5$ sweeps of the lattice.

\subsubsection{Temperature $T = 2.4\;\text{kT/J}$}

For the lattice at temperature $T = 2.4\;\text{kT/J}$, we have the results as seen in figure \ref{fig:ordertemp2ener} and \ref{fig:ordertemp2magn}. In figure \ref{fig:ordertemp2ener}, we have the mean energy per spin for both an orderly and randomly initiated lattice, and in figure \ref{fig:ordertemp2magn}, we see the mean (absolute) magnetization per spin for both an orderly and randomly initiated lattice.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.38]{temp2ener.png}
    \caption{Expectation value of the energy (per spin) as a function of the amount of full sweeps of the lattice, for both a randomly and orderly initiated lattice. The Lattice is dimensionality $20\times20$. We see no preference in the convergence rate between the orderly and randomly initiated spins. Both values seem to be "calming down" around 1 million sweeps, and we say that it has reached a steady state just barely.}
    \label{fig:ordertemp2ener}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.35]{temp2magn.png}
    \caption{Expectation value of the (absolute) magnetization (per spin) as a function of the amount of full sweeps of the lattice. We can see that here, just like in figure \ref{fig:ordertemp2ener}, that there is no preference whether we initiate the lattice with a random or orderly system. We assume that we just barely have reached the steady state in this case for 1 million sweeps.}
    \label{fig:ordertemp2magn}
\end{figure}

For the chosen temperature $T = 2.4\;\text{kT/J}$, we see that the randomly initiated lattice more or less converges just as quickly as the orderly initiated one (though it is more sporadic in the beginning than its orderly initiated counterpart). It is also difficult to say whether or not the functions have truly converged after 1 million iterations, as both values seem to change significantly even after 1 million sweeps. For this reason, we will choose to do 10 million sweeps when we study the phase transition closer. We will also say that we will have reached the steady state for this temperature when we have done 1 million Monte Carlo sweeps.

\subsection{Probability Distribution}

The probability distributions of the energies of a $20\times20$-lattice after the steady state has been reached can be seen in figures \ref{fig:histo1} and \ref{fig:histo2}. We say that a proper steady state has been reached after 1 million MC sweeps have been run through. We then run through 9 million sweeps to collect data. It is worth noting that in both figures \ref{fig:histo1} and \ref{fig:histo2}, the energies are the total energies of the lattice, and not the energy-per-spin quantity as presented in the previous results.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{histo1.png}
    \caption{Histogram of obtained energy values for temperature $T = 1.0\;\text{kT/J}$ after the steady state has been reached. As we can see, there is a sharp peak around the lowest energy that can be obtained, with some energies in the following few lowest energy states. For the most part peaked around the lowest energy.}
    \label{fig:histo1}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{histo2.png}
    \caption{Histogram of obtained energy values for temperature $T = 2.4\;\text{kT/J}$ after the steady state has been reached. Here, the results are more spread out, and the mean of the energy is not focused around the lowest energy state, but rather a higher energy of $~\;-480J$ energy units.}
    \label{fig:histo2}
\end{figure}

As we can see in figure \ref{fig:histo2}, we have a pretty clear Boltzmann-distribution among the states. It is not as clear in figure \ref{fig:histo1}, but for low temperatures, the Boltzmann-distribution is given as being centered around the lowest obtainable energy level, and as such is a result just as expected.
\\
\\
Note that these results are not normalized in figures \ref{fig:histo1} and \ref{fig:histo2}, and it is the distribution that is vital, not as much the actual value on the y-axis.

\subsection{Studies of Phase Transition}

\subsubsection{Simulated values}

In figures \ref{fig:ET}-\ref{fig:susT}, we have the results for the full simulation of 4 different $L \times L$ lattices for $L \in \{40,60,80,100\}$. In figure \ref{fig:ET} we have the mean energy of the lattices as a function of temperature $T$. In figure \ref{fig:MT} we have the mean (absolute) magnetization of the lattices as a function of temperature. In figure \ref{fig:CVt} we have the heat capacity of the lattices as a function of temperature. In figure \ref{fig:susT}, we have the susceptibility of the lattices as a function of temperature. Due to time constraints, we have chosen to only do $10^5$ sweeps to calibrate the lattice into the steady state before starting to collect data. In total, $10^6$ sweeps have been done, where the final $90\%$ is the collection of data.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{ET.png}
    \caption{Expectation values of the energy per spin $\langle E \rangle/L^2$ of a given $L\times L$-lattice. These results behave differently than we would expect it to do, and as such it is reason to throw away these results altogether.}
    \label{fig:ET}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{MT.png}
    \caption{Expectation values of the absolute magnetization per spin $\langle |\mathcal{M}|\rangle/L^2$ of a given $L\times L$-lattice, as a function of temperature $T$. We have simulated for $T \in [2,2.3]$ with $\Delta T = 0.05$. We see that, as the temperature increases, the magnetization drops drastically.}
    \label{fig:MT}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{CVt.png}
    \caption{Heat capacity per spin $C_v/L^2$ of a given $L\times L$-lattice as a function of temperature $T$. We have simulated for $T \in [2,2.3]$ with $\Delta T = 0.05$. These results behave somewhat as expected, with an apparent peak just inside our temperature span somewhere in $T \in [2.25,2.3]$.}
    \label{fig:CVt}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.45]{susT.png}
    \caption{Susceptibility per spin $\chi/L^2$ of a given $L\times L$-lattice as a function of temperature $T$. We have simulated for $T \in [2,2.3]$ with $\Delta T = 0.05$. These results are really chaotic and it is impossible to really say anything from these plots at all.}
    \label{fig:susT}
\end{figure}

The plots from figures \ref{fig:ET} and \ref{fig:susT} give us unexpected values, and as such we can't deduct anything from these data sets. The plot in figure \ref{fig:MT} give us somewhat the expected behaviour of the magnetization of the lattice, where it drops for higher values of $T$. THe plot in figure \ref{fig:CVt} also give us somewhat expected behaviour, just that the apparent peak if somewhere to the right of our data collection set. Among these plots, only figures \ref{fig:MT} and \ref{fig:CVt} has meaningful results that we can work with.

\newpage

\subsubsection{Critical Temperature at Thermodynamic Limit}

Considering that the plots from the simulations (in figures \ref{fig:ET}-\ref{fig:susT}) are questionable at best, we can't really deduct anything meaningful about what the critical temperature of this lattice is. Looking at figures \ref{fig:MT} and \ref{fig:CVt} however, we could maybe deduct that the critical temperature should be somewhere in the range $T \in [2.25,2.30]$, but with our results we can't really say anything more for certain than that.

\newpage

\section{Discussion}

\subsection{Program Functionality}

A good way of confirming whether or not our program is running as planned is by comparing it with an analytical calculated value. Considering that this requires us to calculate the partition function for a state, which means that we need to calculate a value for every single microstate, we will have to limit ourselves to the $2\times2$-lattice case. The analytic values for the mean energy $\langle E \rangle$, mean magnetization $\langle \mathcal{|M|}\rangle$, heat capacity $C_v$ and susceptibility $\chi$ are calculated in appendix \ref{app:2times2}, and also written down at the top of table \ref{tab:analvsnumerical}. In this table, we also see numerical approximations to the same values using the already discussed methods. 
\\
\\
From this table, we can clearly see that all of the calculated values seem to converge to the analytic value for the $2\times2$-lattice for temperature $T = 1.0\;\text{kT/J}$. This therefore gives us the confirmation we need as to if our program is functioning as expected. We can also see that, for $N = 10^7$ MC sweeps, we actually get quite accurate results as well. How this however scales for higher values of temperature $T$ and lattice size $L\times L$ is however difficult to say from this one set of simulations.

\subsection{Stabilization Process}

Looking at figures \ref{fig:randtemp1ener} and \ref{fig:randtemp1magn}, we can see that the convergence toward a steady state happens so much quicker for the lower temperatures as opposed to the higher temperatures in figures \ref{fig:ordertemp2ener} and \ref{fig:ordertemp2magn}. This is probably due to the fact that the likelyhood of swapping to higher energy states increases with temperature ($e^{-\beta\Delta E}$ increases with temperature), and as such it more often obtains a wider variety of values. One could also note that we got a much quicker convergence for the ordered state for $T = 1.0$, but for the $T = 2.4$-case saw no difference between random and ordered initiated lattices. As such, for simplicity's sake, we will choose to initiate with an ordered lattice instead of a random one, in lack of seeing any improvements with the randomly initiated one.
\\
\\
Considering that the results for $T = 2.4$ seems to stabilize at around $~10^6$ full Monte Carlo sweeps, and under the assumption that the higher the temperature, the slower the convergence rate (which is logical considering that $e^{-\beta\Delta E}$ grows larger for higher temperatures), we will assume that we would need to do this amount of sweeps before starting to collect data for our simulation. This is to best ensure that the data we get don't receive any noise from the "extremities" of the values in the start of the simulation.
\\
\\
One should note that, due to the time constraints we had, the simulation for $10^6$ sweeps to stabilize and $10^7$ sweeps total, even with flags and parallelization, was a too daunting task. Therefore, we had to resort to doing an order of magnitude lower amount of sweeps, which (probably) greatly distorted the results.

\subsection{Probability Distribution}

As expected, the probability distribution we got in figures \ref{fig:histo1} and \ref{fig:histo2} seem to follow the Boltzmann distribution. This is the expected behaviour of this system after reaching the steady state, and as such we can at least deduct that these results seem probable. The distribution itself should have been plotted on top of a (normalized) histogram plot, to see the striking similarity. We haven't looked closer at the standard deviation either, unfortunately, and this should be done to further show that we're actually dealing with the Boltzmann-distribution. 
\\
\\
In figure \ref{fig:histo1}, there is a bar missing, which probably stems from us having more bars than there is obtainable values. This is a quick-fix that would simply require us to have the correct amount of bars as there as states, and should have been done. Due to time constraints however, I choose to only acknowledge the whitespace between the bars in the histogram.

\subsection{Phase Transition \& Critical Temperature}

Looking at figures \ref{fig:ET}-\ref{fig:susT}, we see pretty inconclusive data regarding the critical temperature and the expected behaviour as a whole. Looking at the susceptibility in \ref{fig:susT}, we see somewhat an expected increase in the susceptibility around somewhat the same area of the temperature-diagram, however it is chaotic at best, and doesn't really tell us anything. The same applies for the mean energy in figures \ref{fig:ET}.
\\
\\
The mean magnetization in figure \ref{fig:MT}, we see a somewhat expected drop in magnetization, and from the results, we could at least believe that the critical temperature $T_C$ should be somewhere above $T = 2.25$. For the heat capacity $C_v$ in figure \ref{fig:CVt}, it seems like we have passed the "peak" at $T = 2.30$, and as such the critical temperature $T_C$ should be below $T = 2.30$. This gives us the span $T_C \in [2.25,2.30]$ to look for, but we can't really narrow our domain down any further with the results we've got.
\\
\\
According to Lars Onsager, the critical temperature $T_C = \frac{2}{\ln{(1+\sqrt{2)}}} \approx 2.269$ for our given lattice in the thermodynamic limit. Our approximation for this critical temperature of being somewhere in the span $T \in [2.25,2.30]$ is somewhat reasonable, but it is not sufficiently accurate considering that this is a numerical approximation.
\\
\\
The reason for these plots not giving any sensible data might be because of the time constraints that occurred during simulations. Due to a failed overnight run due to the OS of the computer in question crashing several times, we were forced to do shorter runs with $10^6$ sweeps in total instead of the planned $10^7$. Incidentally, this also meant that we had to shorten our planned calibration time from $10^6$ to $10^5$ sweeps so that we had enough data to return a representative calculated mean value. 
\\
\\
Another probable culprit for us having poor results might be because of the high $\Delta T$. With a greater temperature resolution, especially in the range between $T \in [2.25,2.30]$, we might have gotten a better measure on the critical temperature $T_C$.

\section{Conclusion}

We have looked closer at numerical approximations at the Ising model of a magnetized 2-dimensional lattice. After doing some simulations for a small $2\times2$-lattice, we have seen that our model works fine, and converges toward the analytic value for $10^6$ full Monte Carlo sweeps of the lattice. The expectation values seem to stabilize at around $N ~ 10^6$ sweeps as well, and after extracting the expectation values of the energy after stabilization, we see that the energies follow the Boltzmann distribution as expected.
\\
\\
The values that we got from trying to analyze the phase transition were poor, and the lack of usable results probably stems from a low amount of Monte Carlo sweeps in our simulations, as well as a low resolution of the temperature $T$, especially within the span $T \in [2.25,2.30]$. Given more processing time to both increase the amount of Monte Carlo sweeps, as well as having a lower $\Delta T$, we could have determined the critical temperature at a much more accurate level.

\newpage

\begin{appendix}

\section{Analytical expressions for a $2\times2$ lattice}\label{app:2times2}

To validate our results for the $n\times n$ lattice, we would like to have something to compare it to. Since the amount of microstates in a $n\times n $ lattice grows in the order of $2^{n\cdot n}$, we will resort to only calculate this for the $2\times 2$-case, which includes 16 microstates. We sort these microstates by the amount of spins pointing up ($N_\uparrow$) in each of them. For the $2\times2$-lattice case, we note that we got 4 particles and 8 nodes. (In general for $L\times L$ quadratic lattice we've got $L^2$ particles and $2L^2$ links connecting them.
\\
\\
For the case where all 4 spins point up, there is only one configuration that correspond to this. We can therefore say that this has a degeneracy of 1. The magnetization of this microstate is the sum of each individual particles' spin (as in equation \ref{eq:magneticlat}), and is therefore trivially $\mathcal{M}_{4\uparrow} = 4$. The energy is given as in equation \ref{eq:enerlat}, and we sum up all of the associated energies of the links connecting the nodes. Since we have 8 nodes, and all of the spins are pointed in the same direction, this gives us:
$$
E_{4\uparrow} = -J\sum\limits_{i=1}^8 1 = -8J
$$
As the energy for the 1 microstate with all spins pointing up. Likewise, for all spins pointing down, we get the energy as:
$$
E_{0\uparrow} = -J\sum\limits_{i=1}^8 1 = -8J
$$
However, for the case with no spins pointing up, we have the magnetization given as $\mathcal{M}_{0\uparrow} = -4$.
\\
\\
For the state with 3 spins pointing up, we have 4 different configurations to choose from. (1 spin pointing down, this spin can take 1 of 4 different positions). This means that this state will have a degeneracy of 4. This state will have 3 "magnets" pointing up, and 1 pointing down, giving a total magnetization $\mathcal{M}_{3\uparrow} = 2$. Regarding the energy, we have that 4 out of the 8 nodes are linked with the down-spin, while the rest of the links are connected between up-spins. This gives us the energy using equation \ref{eq:enerlat} as:
$$
E_{3\uparrow} = -J\Bigg[\sum\limits_{i=1}^4 \Big[1\cdot1\Big] + \sum\limits_{i=1}^4 \Big[1\cdot(-1)\Big]\Bigg] = 4-4 = 0
$$
The same logic can also be applied for the case with 1 spin pointing up, such that:
$$
E_{1\uparrow} = 0
$$
However, for this case we got that the magnetization will be $\mathcal{M}_{1\uparrow} = -2$. This case will also have a degeneracy of 4 following the same logic as above.
\\
\\
Finally, we got the case for 2 spins pointing up. Here, we got 6 different configurations with 2 distinct properties. All of these configurations will have 2 spins up and 2 spins down, leading to the magnetization $\mathcal{M}_{2\uparrow} = 0$. Now, we will first look at the case where the up-spins are located diagonally in regards to each other. For this case, we have 2 different configurations (up-spins in top right and lower left corner, and in top left and lower right). This means that every single node will be connected with an opposite spin, and we will sum over 8 negatives. This gives us, using equation \ref{eq:enerlat}, that:
$$
E_{2\uparrow,1} = -J\sum\limits_{i=1}^8 1\cdot(-1) = -J(-8) = 8J
$$
Now, we will look at the case where the spins are located right next to each other. For this case, we get 4 links connecting identical spins, and 4 links connecting opposite spins. Just as in the $E_{3\uparrow}$ and $E_{1\uparrow}$ case, we will therefore got:
$$
E_{2\uparrow,2} = 0
$$
Counting up all of these states, we see that we've reached 16 microstates, meaning we've gotten through all of the possible configurations. This gives us the table of values for the magnetization and energy of each of the states that we can see in table \ref{tab:apptable}.
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
         $N_{\uparrow}$ (\# Spins Up) & Degeneracy &$\;\;\;E\;\;\;$&$\;\;\;\mathcal{M}\;\;\;$  \\
         \hline\hline
         $4$&$1$&$-8J$&$4$ \\
         $3$&$4$&$0$&$2$\\
         $2$&$4$&$0$&$0$\\
         $2$&$2$&$8J$&$0$\\
         $1$&$4$&$0$&$-2$\\
         $0$&$1$&$-8J$&$-4$\\
         \hline
    \end{tabular}
    \caption{All the different microstates together with corresponding degeneracy, energy and magnetization of that microstate}
    \label{tab:apptable}
\end{table}
We can now use these values to calculate the mean energy $\langle E \rangle$, the mean absolute value of the magnetic moment $\langle | \mathcal{M} | \rangle$, the heat capacity of the lattice $C_v$ and the magnetic susceptibility $\chi$. First, we use equation \ref{eq:partition} to calculate the partition function:
$$
Z = \sum\limits_{i=1}^{16} e^{-\beta E(S)}
$$
2 of the states have $E(s) = -8J$, 2 of the states have $E(s) = 8J$, and the remaining 12 states have $E(s) = 0$. Doing the sum, and setting $J = 1$, gives us:
$$
Z = 2e^{-8\beta} + 2e^{8\beta} + 12 \approx 5973.9166 
$$
Now, we can use this to calculate the expectation values $\langle E \rangle$, $\langle |\mathcal{M}|\rangle$, $\langle \mathcal{M}\rangle$, $\langle E^2 \rangle$ and $\langle \mathcal{M}^2\rangle$. Using equation \ref{eq:generalmean}, and inserting for our partition function, the following values can be shown to be true (we set Boltzmanns constant $k = 1$ and temperature $T = 1$):
\begin{equation}\label{eq:laneran}
    \langle E \rangle = -\frac{8\sinh{(8\beta)}}{\cosh{(8\beta)}+3}
\end{equation}
\begin{equation}\label{eq:lane2ran}
    \langle E^2\rangle = \frac{64\cosh{(8\beta)}}{\cosh{(8\beta)}+3}
\end{equation}
\begin{equation}\label{eq:lanmran}
    \langle \mathcal{M} \rangle = 0
\end{equation}
\begin{equation}\label{eq:lanm2ran}
    \langle \mathcal{M}^2 \rangle = \frac{8e^{8\beta}+8}{\cosh{(8\beta)}+3}
\end{equation}
\begin{equation}
    \langle |\mathcal{M}|\rangle = \frac{2e^{8\beta}+4}{\cosh{(8\beta)}+3}
\end{equation}
These can be left as an exercise for the reader to show. By using equation \ref{eq:hctheory}, inserting values from equations \ref{eq:laneran} and \ref{eq:lane2ran}, we can calculate the $C_v$ to be:
\begin{equation}
    C_v = \frac{1}{T^2}\Bigg[\frac{64\cosh{(8\beta)}}{\cosh{(8\beta)}+3}-\bigg(\frac{8\sinh{(8\beta)}}{\cosh{8\beta + 3}}\bigg)^2\Bigg]
\end{equation}
By using equation \ref{eq:chitheory}, inserting values from equation \ref{eq:lanmran} and \ref{eq:lanm2ran}, we can calculate the susceptibility to be:
\begin{equation}
    \chi = \frac{1}{T}\frac{8e^{8\beta}+4}{\cosh{8\beta}+3}
\end{equation}
From this, having set $\beta = 1$, we can deduct the following values that we can test with our numerical simulation:
\begin{equation}
    \langle E \rangle \approx -1.99598
\end{equation}
\begin{equation}
    \langle |\mathcal{M}|\rangle \approx 0.9986607
\end{equation}
\begin{equation}
    C_v \approx 0.03208233
\end{equation}
\begin{equation}
    \chi \approx 3.9933038
\end{equation}
These can be compared to the numerical approximations that we create, and the comparison can be seen in table \ref{tab:analvsnumerical}.

\onecolumngrid

\end{appendix}

\end{document}

